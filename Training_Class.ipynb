{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMaIVN4GMbFBgrsx1hOYAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rooncal/Image-Segmentation/blob/main/Training_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8a-FZs-d32X"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hlJg-oeg-f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "0099beaf-a18d-493c-817d-8965321b936a"
      },
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "!pip install scipy==1.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/de/0c22c6754370ba6b1fa8e53bd6e514d4a41a181125d405a501c215cbdbd6/scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 155kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "scipy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q2fpP7Sd6Qf"
      },
      "source": [
        "##Cloning model from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDvXr6BJSFbn",
        "outputId": "6e7ecc1e-73cc-4cdc-cb26-2ef3fffa998a"
      },
      "source": [
        "!git clone https://github.com/jacobkimmel/fcdensenet_pytorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fcdensenet_pytorch'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Total 90 (delta 0), reused 0 (delta 0), pack-reused 90\u001b[K\n",
            "Unpacking objects: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTWeCnlceDf0"
      },
      "source": [
        "##Importing related classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "SZZm3XSWY9-m",
        "outputId": "5c70b743-7d9c-4b98-9165-c348defca316"
      },
      "source": [
        "sys.path.append(\"/content/fcdensenet_pytorch/\")\n",
        "from fcdensenet_pytorch.model import DenseNet103\n",
        "from fcdensenet_pytorch.trainer import DiceLoss\n",
        "from fcdensenet_pytorch.data_loader import CellDataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f2ac3209c7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfcdensenet_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDenseNet103\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfcdensenet_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiceLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfcdensenet_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCellDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/fcdensenet_pytorch/data_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimsave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#imresize = resize # alias old scipy.misc.imresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'imresize' from 'scipy.misc' (/usr/local/lib/python3.7/dist-packages/scipy/misc/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Avd__PNe_8-"
      },
      "source": [
        "##Getting data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZDbt6bJhFXz"
      },
      "source": [
        "This line downloads and decompresses the dataset to a folder named \"data\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGHjU43jfB5f",
        "outputId": "b85a3b49-ac8c-4b87-d978-b6f9de9b8d9f"
      },
      "source": [
        "!if [[ ! -e data ]]; then wget http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamSeq01/CamSeq01.zip; unzip -qq CamSeq01.zip -d data; rm -f CamSeq01.zip; fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-08 10:33:38--  http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamSeq01/CamSeq01.zip\n",
            "Resolving mi.eng.cam.ac.uk (mi.eng.cam.ac.uk)... 129.169.82.147\n",
            "Connecting to mi.eng.cam.ac.uk (mi.eng.cam.ac.uk)|129.169.82.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94535380 (90M) [application/zip]\n",
            "Saving to: ‘CamSeq01.zip’\n",
            "\n",
            "CamSeq01.zip        100%[===================>]  90.16M  21.6MB/s    in 9.0s    \n",
            "\n",
            "2021-05-08 10:33:47 (10.0 MB/s) - ‘CamSeq01.zip’ saved [94535380/94535380]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1ShRZTbjUQZ",
        "outputId": "e9a41cbd-fafc-46d0-e65b-216fead3a5d5"
      },
      "source": [
        "!rm -f data/*.txt\n",
        "!mkdir labels\n",
        "!mv data/*L.png labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘labels’: File exists\n",
            "mv: cannot stat 'data/*L.png': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "E26EjEhTi6yp",
        "outputId": "441c189f-7498-422d-feb7-43e20bafd7ae"
      },
      "source": [
        "train_set = CellDataset('/content/data', '/content/labels')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-275733dc2115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCellDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'CellDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0uISEzoeIz-"
      },
      "source": [
        "##Our training class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pK3BcGchEOB"
      },
      "source": [
        "class Trainer():\n",
        "  def __init__(self, model, loss_function, optimizer, train_dataloader, start_epoch=0, val_dataloader=None, tqdm=True,\n",
        "               tensorboard_log_dir='', lr_scheduler=None, model_checkpoint_dir='', experiment_name='model_training'):\n",
        "    self.model = model\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.loss_function = loss_function\n",
        "    self.epoch = start_epoch\n",
        "    self.optimizer = optimizer\n",
        "    self.train_dataloader = train_dataloader\n",
        "    self.val_dataloader = val_dataloader\n",
        "    self.tensorboard_log_dir = ''\n",
        "    self.lr_scheduler = lr_scheduler\n",
        "    self.model_checkpoint_dir = model_checkpoint_dir\n",
        "    self.tqdm = tqdm\n",
        "    self.experiment_name = experiment_name\n",
        "\n",
        "\n",
        "    def train(self, total_epochs, checkpoint_interval=10):\n",
        "      for self.epoch in range(self.epoch, total_epochs):\n",
        "        self.train_iter()\n",
        "        if self.val_dataloader:\n",
        "          self.val_iter()\n",
        "        if checkpoint_interval % epoch == 0:\n",
        "          save_checkpoint()\n",
        "\n",
        "\n",
        "    def train_iter(self):\n",
        "      running_loss = 0\n",
        "      self.model.train()\n",
        "\n",
        "      if self.tqdm:\n",
        "        self.train_dataloader = tqdm(self.train_dataloader)\n",
        "\n",
        "      for (image, mask) in self.train_dataloader:\n",
        "        self.optimizer.zero_grad()\n",
        "        image, mask = image.to(self.device), mask.to(self.device, dtype=torch.long).squeeze(1)\n",
        "        output = self.model(image)\n",
        "        loss = self.loss_function(output, mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "      \n",
        "      print(f\"Epoch: {self.epoch}, Training Loss: {running_loss}\")\n",
        "      return running_loss\n",
        "\n",
        "    def val_iter(self):\n",
        "      self.model.eval()\n",
        "      if self.tqdm:\n",
        "        self.val_dataloader = tqdm(self.val_dataloader)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        running_loss = 0\n",
        "        for (image, mask) in self.val_dataloader:\n",
        "          image, mask = image.to(self.device), mask.to(self.device,dtype=torch.long).squeeze(1)\n",
        "          output = self.model(mask)\n",
        "          loss = self.loss_function(output, mask)\n",
        "          running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch: {self.epoch}, Validation Loss: {running_loss}\")\n",
        "        return running_loss\n",
        "    \n",
        "    def save_checkpoint(self):\n",
        "      torch.save({\n",
        "            'epoch': self.epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            }, os.path.join(model_checkpoint_dir,self.experiment_name,f\"checkpoint_{self.epoch}\")) \n",
        "        \n",
        "    def load_checkpoint(self, path, epoch=0):\n",
        "      if epoch and not path:\n",
        "        path = os.path.join(model_checkpoint_dir,self.experiment_name,f\"checkpoint_{epoch}\")\n",
        "      checkpoint = torch.load(path)\n",
        "      self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      self.epoch = checkpoint['epoch']\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqM0kSv8eM2C"
      },
      "source": [
        "##Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXRcefilYgj4"
      },
      "source": [
        "densenet = DenseNet103()\n",
        "optimizer = torch.optim.RMSprop(densenet.parameters())\n",
        "densenet_trainer = Trainer(model=DenseNet103,loss_function=DiceLoss,optimizer=optimizer,)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}